{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Model Training\n",
    "The following code blocks were used for training the triplet loss model. \n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Got help from multiple web sources, notably:\n",
    "# https://stackoverflow.com/questions/47727679/triplet-model-for-image-retrieval-from-the-keras-pretrained-network\n",
    "# https://ksaluja15.github.io/Learning-Rate-Multipliers-in-Keras/\n",
    "# https://keras.io/preprocessing/image/\n",
    "# https://github.com/keras-team/keras/issues/3386\n",
    "# https://github.com/keras-team/keras/issues/8130\n",
    "# https://github.com/noelcodella/tripletloss-keras-tensorflow\n",
    "\n",
    "\n",
    "\n",
    "# GLOBAL DEFINES\n",
    "WIDTH = 96\n",
    "HEIGHT = 96\n",
    "CHANNELS = 3\n",
    "SEED = 1337\n",
    "\n",
    "import sys\n",
    "import ssl \n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# TensorFlow Includes\n",
    "import tensorflow as tf\n",
    "#from tensorflow.contrib.losses import metric_learning\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Keras Imports & Defines \n",
    "import keras\n",
    "import keras.applications\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import keras.layers as kl\n",
    "from keras.layers import Input, Layer\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from model import create_model\n",
    "\n",
    "\n",
    "from keras.legacy import interfaces\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Optimizer\n",
    "\n",
    "import keras as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# Generator object for data augmentation.\n",
    "# Can change values here to affect augmentation style.\n",
    "datagen = ImageDataGenerator(  rotation_range=90,\n",
    "                                width_shift_range=0.05,\n",
    "                                height_shift_range=0.05,\n",
    "                                zoom_range=0.1,\n",
    "                                horizontal_flip=True,\n",
    "                                vertical_flip=True,\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimiser\n",
    " As hilighted in the report, a SGD optimiser was used to update the learning rates for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class LR_SGD(Optimizer):\n",
    "    \"\"\"Stochastic gradient descent optimizer.\n",
    "\n",
    "    Includes support for momentum,\n",
    "    learning rate decay, and Nesterov momentum.\n",
    "\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        momentum: float >= 0. Parameter updates momentum.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=0.01, momentum=0., decay=0.,\n",
    "                 nesterov=False,multipliers=None,**kwargs):\n",
    "        super(LR_SGD, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n",
    "            self.momentum = K.variable(momentum, name='momentum')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "        self.initial_decay = decay\n",
    "        self.nesterov = nesterov\n",
    "        self.lr_multipliers = multipliers\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        learning_rate = self.learning_rate\n",
    "        if self.initial_decay > 0:\n",
    "            learning_rate *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                  K.dtype(self.decay))))\n",
    "        # momentum\n",
    "        shapes = [K.int_shape(p) for p in params]\n",
    "        moments = [K.zeros(shape) for shape in shapes]\n",
    "        self.weights = [self.iterations] + moments\n",
    "        for p, g, m in zip(params, grads, moments):\n",
    "            \n",
    "            matched_layer = [x for x in self.lr_multipliers.keys() if x in p.name]\n",
    "            if matched_layer:\n",
    "                new_lr = learning_rate * self.lr_multipliers[matched_layer[0]]\n",
    "            else:\n",
    "                new_lr = learning_rate\n",
    "\n",
    "            v = self.momentum * m - new_lr * g  # velocity\n",
    "            self.updates.append(K.update(m, v))\n",
    "\n",
    "            if self.nesterov:\n",
    "                new_p = p + self.momentum * v - new_lr * g\n",
    "            else:\n",
    "                new_p = p + v\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'learning_rate': float(K.get_value(self.learning_rate)),\n",
    "                  'momentum': float(K.get_value(self.momentum)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'nesterov': self.nesterov}\n",
    "        base_config = super(LR_SGD, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "Generator function for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def createDataGen(X1, X2, X3, Y, b):\n",
    "\n",
    "    local_seed = T_G_SEED\n",
    "    genX1 = datagen.flow(X1,Y, batch_size=b, seed=local_seed, shuffle=False)\n",
    "    genX2 = datagen.flow(X2,Y, batch_size=b, seed=local_seed, shuffle=False)\n",
    "    genX3 = datagen.flow(X3,Y, batch_size=b, seed=local_seed, shuffle=False)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            X3i = genX3.next()\n",
    "\n",
    "            yield [X1i[0], X2i[0], X3i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model\n",
    "This function creates the model to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def createModel(emb_size):\n",
    "\n",
    "    # Initialize a ResNet50_ImageNet Model\n",
    "    resnet_input = kl.Input(shape=(WIDTH,HEIGHT,CHANNELS))\n",
    "    resnet_model = keras.applications.resnet50.ResNet50(weights='imagenet', include_top = False, input_tensor=resnet_input)\n",
    "\n",
    "    # New Layers over ResNet50\n",
    "    net = resnet_model.output\n",
    "    net = kl.GlobalAveragePooling2D(name='gap')(net)\n",
    "    net = kl.Dense(emb_size,activation='relu',name='t_emb_1')(net)\n",
    "    net = kl.Lambda(lambda  x: K.l2_normalize(x,axis=1), name='t_emb_1_l2norm')(net)\n",
    "\n",
    "    # model creation\n",
    "    base_model = Model(resnet_model.input, net, name=\"base_model\")\n",
    "\n",
    "    # triplet framework, shared weights\n",
    "    input_shape=(WIDTH,HEIGHT,CHANNELS)\n",
    "    input_anchor = kl.Input(shape=input_shape, name='input_anchor')\n",
    "    input_positive = kl.Input(shape=input_shape, name='input_pos')\n",
    "    input_negative = kl.Input(shape=input_shape, name='input_neg')\n",
    "\n",
    "    net_anchor = base_model(input_anchor)\n",
    "    net_positive = base_model(input_positive)\n",
    "    net_negative = base_model(input_negative)\n",
    "\n",
    "    # The Lamda layer produces output using given function. Here its Euclidean distance.\n",
    "    positive_dist = kl.Lambda(euclidean_distance, name='pos_dist')([net_anchor, net_positive])\n",
    "    negative_dist = kl.Lambda(euclidean_distance, name='neg_dist')([net_anchor, net_negative])\n",
    "    tertiary_dist = kl.Lambda(euclidean_distance, name='ter_dist')([net_positive, net_negative])\n",
    "\n",
    "    # This lambda layer simply stacks outputs so both distances are available to the objective\n",
    "    stacked_dists = kl.Lambda(lambda vects: K.stack(vects, axis=1), name='stacked_dists')([positive_dist, negative_dist, tertiary_dist])\n",
    "\n",
    "    model = Model([input_anchor, input_positive, input_negative], stacked_dists, name='triple_siamese') \n",
    "    \n",
    "    \n",
    "    # Setting up optimizer designed for variable learning rate\n",
    "\n",
    "    # Variable Learning Rate per Layers\n",
    "    lr_mult_dict = {}\n",
    "    last_layer = ''\n",
    "    for layer in resnet_model.layers:\n",
    "        # comment this out to refine earlier layers\n",
    "        # layer.trainable = False  \n",
    "        # print layer.name\n",
    "        lr_mult_dict[layer.name] = 1\n",
    "        # last_layer = layer.name\n",
    "    lr_mult_dict['t_emb_1'] = 100\n",
    "\n",
    "    base_lr = 0.1\n",
    "    momentum = 0.9\n",
    "    v_optimizer = LR_SGD(learning_rate=base_lr, momentum=momentum, decay=0.0, nesterov=False, multipliers = lr_mult_dict)\n",
    "   \n",
    "    model.compile(optimizer=v_optimizer, loss=triplet_loss, metrics=[accuracy])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet Loss\n",
    "\n",
    "Implements triplet loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred):\n",
    "    margin = K.constant(1)\n",
    "    return K.mean(K.maximum(K.constant(0), K.square(y_pred[:,0,0]) - 0.5*(K.square(y_pred[:,1,0])+K.square(y_pred[:,2,0])) + margin))\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(y_pred[:,0,0] < y_pred[:,1,0])\n",
    "\n",
    "def l2Norm(x):\n",
    "    return  K.l2_normalize(x, axis=-1)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loads an image and preprocesses\n",
    "def read_image(loc):\n",
    "    t_image = cv2.imread(loc)\n",
    "    t_image = cv2.resize(t_image, (HEIGHT,WIDTH))\n",
    "    t_image = t_image.astype(\"float32\")\n",
    "    t_image = keras.applications.resnet50.preprocess_input(t_image, data_format='channels_last')\n",
    "\n",
    "    return t_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read image list\n",
    "The function below loads a set of images from a text index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_image_list(flist, start, length):\n",
    "\n",
    "    with open(flist) as f:\n",
    "        content = f.readlines() \n",
    "    #print(flist)\n",
    "    #print(content)\n",
    "    content = [x.strip().split()[0] for x in content] \n",
    "\n",
    "    datalen = length\n",
    "    if (datalen < 0):\n",
    "        datalen = len(content)\n",
    "\n",
    "    if (start + datalen > len(content)):\n",
    "        datalen = len(content) - start\n",
    " \n",
    "    imgset = np.zeros((datalen, HEIGHT, WIDTH, CHANNELS))\n",
    "\n",
    "    for i in range(start, start+datalen):\n",
    "        if ((i-start) < len(content)):\n",
    "            imgset[i-start] = read_image(content[i])\n",
    "\n",
    "    return imgset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract\n",
    "Extracts model weights, for a given set of images and writes them to a textfile. Also produces a single array list input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract(argv):\n",
    "\n",
    "    if len(argv) < 3:\n",
    "        print (\"Usage: \\n\\t <Model Prefix> <Input Image List (TXT)> <Output File (TXT)> \\n\\t\\tExtracts triplet-loss model\")\n",
    "        return\n",
    "\n",
    "    modelpref = argv[0]\n",
    "    imglist = argv[1]\n",
    "    outfile = argv[2]\n",
    "\n",
    "    with open(modelpref + '.json', \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "\n",
    "    loaded_model = keras.models.model_from_json(model_json)\n",
    "    loaded_model.load_weights(modelpref + '.h5')\n",
    "\n",
    "    base_model = loaded_model.get_layer('base_model')\n",
    "\n",
    "    # create a new single input\n",
    "    input_shape=(WIDTH,HEIGHT,CHANNELS)\n",
    "    input_single = kl.Input(shape=input_shape, name='input_single')\n",
    "    \n",
    "    # create a new model without the triple loss\n",
    "    net_single = base_model(input_single)\n",
    "    model = Model(input_single, net_single, name='embedding_net')\n",
    "    model.save(outfile + '.h5')\n",
    "    \n",
    "    chunksize = 1000\n",
    "    total_img = file_numlines(imglist)\n",
    "    total_img_ch = int(np.ceil(total_img / float(chunksize)))\n",
    "\n",
    "    with open(outfile, 'w') as f_handle:\n",
    "\n",
    "        for i in range(0, total_img_ch):\n",
    "            imgs = read_image_list(imglist, i*chunksize, chunksize)\n",
    "\n",
    "            vals = model.predict(imgs)\n",
    "    \n",
    "            np.savetxt(f_handle, vals)\n",
    "\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn\n",
    "\n",
    "Calls createModel to create the model and then trains it using data in locations specified by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def learn(argv):\n",
    "    \n",
    "    if len(argv) < 10:\n",
    "        print (\"Usage: \\n\\t <Train Anchors (TXT)> <Train Positives (TXT)> <Train Negatives (TXT)> <Val Anchors (TXT)> <Val Positives (TXT)> <Val Negatives (TXT)> <embedding size> <batch size> <num epochs> <output model> \\n\\t\\tLearns triplet-loss model\")\n",
    "        return\n",
    "\n",
    "    in_t_a = argv[0]\n",
    "    in_t_b = argv[1]\n",
    "    in_t_c = argv[2]\n",
    "\n",
    "    in_v_a = argv[3]\n",
    "    in_v_b = argv[4]\n",
    "    in_v_c = argv[5]\n",
    "\n",
    "    emb_size = int(argv[6])\n",
    "    batch = int(argv[7])\n",
    "    numepochs = int(argv[8])\n",
    "    outpath = argv[9] \n",
    "\n",
    "    # chunksize is the number of images we load from disk at a time\n",
    "    chunksize = batch*100\n",
    "    total_t = file_numlines(in_t_a)\n",
    "    total_v = file_numlines(in_v_b)\n",
    "    total_t_ch = int(np.ceil(total_t / float(chunksize)))\n",
    "    total_v_ch = int(np.ceil(total_v / float(chunksize)))\n",
    "\n",
    "    print (\"Dataset has \" + str(total_t) + \" training triplets, and \" + str(total_v) + \" validation triplets.\")\n",
    "\n",
    "    print (\"Creating a model ...\")\n",
    "    model = createModel(emb_size)\n",
    "\n",
    "    print (\"Training loop ...\")\n",
    "    \n",
    "    # manual loop over epochs to support very large sets of triplets\n",
    "    for e in range(0, numepochs):\n",
    "\n",
    "        for t in range(0, total_t_ch):\n",
    "\n",
    "            print ('Epoch ' + str(e) + ': train chunk ' + str(t+1) + '/ ' + str(total_t_ch) + ' ...')\n",
    "\n",
    "            print ('Reading image lists ...')\n",
    "            anchors_t = read_image_list(in_t_a, t*chunksize, chunksize)\n",
    "            positives_t = read_image_list(in_t_b, t*chunksize, chunksize)\n",
    "            negatives_t = read_image_list(in_t_c, t*chunksize, chunksize)\n",
    "            Y_train = np.random.randint(2, size=(1,2,anchors_t.shape[0])).T\n",
    "            \n",
    "            print ('Starting to fit ...')\n",
    "            # This method does NOT use data augmentation\n",
    "            model.fit([anchors_t, positives_t, negatives_t], Y_train, epochs=numepochs,  batch_size=batch)\n",
    "            \n",
    "            # This method uses data augmentation\n",
    "            #model.fit_generator(generator=createDataGen(anchors_t,positives_t,negatives_t,Y_train,batch), steps_per_epoch=len(Y_train) / batch, epochs=1, shuffle=False, use_multiprocessing=True)\n",
    "        \n",
    "        # In case the validation images don't fit in memory, we load chunks from disk again. \n",
    "        val_res = [0.0, 0.0]\n",
    "        total_w = 0.0\n",
    "        for v in range(0, total_v_ch):\n",
    "\n",
    "            print ('Loading validation image lists ...')\n",
    "            print ('Epoch ' + str(e) + ': val chunk ' + str(v+1) + '/ ' + str(total_v_ch) + ' ...')\n",
    "            anchors_v = read_image_list(in_v_a, v*chunksize, chunksize)\n",
    "            positives_v = read_image_list(in_v_b, v*chunksize, chunksize)\n",
    "            negatives_v = read_image_list(in_v_c, v*chunksize, chunksize)\n",
    "            Y_val = np.random.randint(2, size=(1,2,anchors_v.shape[0])).T\n",
    "\n",
    "            \n",
    "            # Weight of current validation measurement. \n",
    "            # if loaded expected number of items, this will be 1.0, otherwise < 1.0, and > 0.0.\n",
    "            w = float(anchors_v.shape[0]) / float(chunksize)\n",
    "            total_w = total_w + w\n",
    "\n",
    "            curval = model.evaluate([anchors_v, positives_v, negatives_v], Y_val, batch_size=batch)\n",
    "            val_res[0] = val_res[0] + w*curval[0]\n",
    "            val_res[1] = val_res[1] + w*curval[1]\n",
    "\n",
    "        val_res = [x / total_w for x in val_res]\n",
    "\n",
    "        print ('Validation Results: ' + str(val_res))\n",
    "\n",
    "    print ('Saving model ...')\n",
    "\n",
    "    # Save the model and weights\n",
    "    model.save(outpath + '.h5')\n",
    "\n",
    "    # Due to some remaining Keras bugs around loading custom optimizers\n",
    "    # and objectives, we save the model architecture as well\n",
    "    model_json = model.to_json()\n",
    "    with open(outpath + '.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    return\n",
    "\n",
    "def file_numlines(fn):\n",
    "    with open(fn) as f:\n",
    "        return sum(1 for _ in f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver\n",
    "\n",
    "This is the 'driver cell'. \n",
    "Arguments are passed into the argv array. A format for passing the arguments can be seen by running the cell without assigning any values to the argv array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \n",
      "\t -learn <Train Anchors (TXT)> <Train Positives (TXT)> <Train Negatives (TXT)> <Val Anchors (TXT)> <Val Positives (TXT)> <Val Negatives (TXT)> <embedding size> <batch size> <num epochs> <output model prefix> \n",
      "\t -extract <Model Prefix> <Input Image List (TXT)> <Output File (TXT)> \n",
      "\t\tBuilds and scores a triplet-loss model \n"
     ]
    }
   ],
   "source": [
    "    \n",
    "argv = []\n",
    "if len(argv) < 2:\n",
    "    print ('Usage: \\n\\t -learn <Train Anchors (TXT)> <Train Positives (TXT)> <Train Negatives (TXT)> <Val Anchors (TXT)> <Val Positives (TXT)> <Val Negatives (TXT)> <embedding size> <batch size> <num epochs> <output model prefix> \\n\\t -extract <Model Prefix> <Input Image List (TXT)> <Output File (TXT)> \\n\\t\\tBuilds and scores a triplet-loss model ')\n",
    "if(len(argv) > 0):\n",
    "    if 'learn' in argv[0]:\n",
    "        learn(argv[1:])\n",
    "    elif 'extract' in argv[0]:\n",
    "        extract(argv[1:])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "The following blocks of code were used to prepare the dataset and also generate graphs for model training interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Copies all images from all folders in a directory into one folder'''\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from skimage import io\n",
    "img_dir = 'dataset'\n",
    "def load_data(data_dir): #lfw is the originalPath\n",
    "\n",
    "    count = 0\n",
    "    print(\"started...\")\n",
    "    for guys in os.listdir(data_dir):\n",
    "        person_dir = pjoin(data_dir, guys)\n",
    "        for i in os.listdir(person_dir):\n",
    "            image_dir = pjoin(person_dir, i)\n",
    "            img22 = io.imread(image_dir, pilmode='RGB')\n",
    "            io.imsave(pjoin(img_dir, i), img22)\n",
    "            count = count+1\n",
    "    print(\"Copied: \" + str(count)\n",
    "    return count\n",
    "\n",
    "sourcepath = 'lfw'\n",
    "load_data(sourcepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method used in the naming of image files in a predefined format to make reading images from index file easy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "def imagedir(basename):\n",
    "    name = basename[0] + \"_\" \n",
    "    if(len(basename[1]) == 1):\n",
    "        name = name + \"000\" + basename[1]\n",
    "    elif(len(basename[1]) == 2):\n",
    "        name = name + \"00\" + basename[1]\n",
    "    elif(len(basename[1]) == 3):\n",
    "        name = name + \"0\" + basename[1]\n",
    "    else:\n",
    "        name = name + basename[1]\n",
    "    data_dir = \"dataset\"\n",
    "    name = name + \".jpg\\n\"\n",
    "    name = pjoin(data_dir, name)\n",
    "    return name\n",
    "\n",
    "print(\"starting...\")       \n",
    "with open('val_individuals.txt') as f1:\n",
    "    with open('val_pairs.txt') as f2:\n",
    "        with open('val_anchor.txt', 'a') as f3:\n",
    "            with open('val_positive.txt', 'a') as f4:\n",
    "                with open('val_negative.txt', 'a') as f5:\n",
    "                    pair_lines = f2.readlines()\n",
    "                    positive = \"\"\n",
    "                    negative = \"\"\n",
    "                    anchor = \"\"\n",
    "                    count = 0\n",
    "                    for line in f1:\n",
    "                        words_ind = line.split()\n",
    "                        \n",
    "                        for pair in pair_lines:\n",
    "                            names = pair.split()\n",
    "                            if(words_ind[0] == names[0]):\n",
    "                                count = count + 1\n",
    "                                pos = imagedir(names[:2])\n",
    "                                neg = imagedir(names[2:])\n",
    "                                anchor = imagedir(words_ind)\n",
    "                                f3.write(anchor)\n",
    "                                f4.write(pos)\n",
    "                                f5.write(neg)\n",
    "                                #print(anchor)\n",
    "                            elif ( names[2] == words_ind[0] ):\n",
    "                                count = count + 1\n",
    "                                pos = imagedir(names[2:])\n",
    "                                neg = imagedir(names[:2])\n",
    "                                anchor = imagedir(words_ind)\n",
    "                                f3.write(anchor)\n",
    "                                f4.write(pos)\n",
    "                                f5.write(neg)\n",
    "                    print(str(count) + \" records written to file\")\n",
    "                        \n",
    "                        \n",
    "                                \n",
    "                    \n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This partitions the dataset into triplets: anchor image, positive and negative images. These are then written to three defferent index files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"starting...\")       \n",
    "with open('anchor.txt', 'r') as f1:\n",
    "    with open('positive.txt', 'r') as f2:\n",
    "        with open('negative.txt', 'r') as f3:\n",
    "            with open(\"a.txt\", \"w\") as fa:\n",
    "                with open(\"b.txt\", \"w\") as fb:\n",
    "                    with open (\"c.txt\", \"w\") as fc:\n",
    "                        count = 0\n",
    "                        for (a, b, c) in zip(f1, f2, f3):\n",
    "                             if(a.strip(\"\\n\") != b.strip(\"\\n\")):\n",
    "                                    fa.write(a)\n",
    "                                    fb.write(b)\n",
    "                                    fc.write(c)\n",
    "                                    count = count + 1\n",
    "                  \n",
    "                #if (count > 1):\n",
    "                 #   print(words_ind[0]+\" \"+str(count))\n",
    "\n",
    "\n",
    "\n",
    "print(\"done \"+ str(count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
